---
title: "p8105_hw2_lz3014"
auther: "Liqi Zhou"
date: 2024-10-02
output: github_document
---

```{r}
library(tidyverse)
library(readxl)
```

# problem 1
### 1.Read, clean and convert the data
```{r}
NYC_subway <- read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
                       na = c("NA",".",""))
NYC_subway_clean <- janitor::clean_names(NYC_subway) |>
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) |>
  mutate(entry = case_match(entry, "YES" ~ TRUE, "NO" ~ FALSE))
NYC_subway_clean
```

### 2.Simple info about this dataset
This dataset contains various variabels related to subways in New York, including *line*, *station name*, *station latitude and longitude*, *routes*, *entry*, *ADA compliance* and so on. To clean the data, firstly, I imported the dataset and used `janitor::clean_names` function to clean up variable names. Then, I used `select` to retain the required variables. Finally, I used `case_match` function to convert the *entry* from character to a logical variable.

After data cleaning process, this data has `r nrow(NYC_subway_clean)` rows and `r ncol(NYC_subway_clean)` columns. These data are not tidy since from route1to route11 can be reduced to one variable. 

### 3.Answer 3 questions
- How many distinct stations are there?
```{r}
station_num <- distinct(NYC_subway_clean, line, station_name) |>
  nrow()
station_num
```

- How many stations are ADA compliant?
```{r}
ADA_station_num <- NYC_subway_clean |>
  filter(ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()
ADA_station_num
```

- What proportion of station entrances / exits without vending allow entrance?
```{r}
ee_novend_en_num <- NYC_subway_clean |>
  filter(vending == "NO" & entry == TRUE) |>
  nrow()
proportion <- ee_novend_en_num/nrow(NYC_subway_clean)
proportion
```

### 4.Reformat data and 2 questions
```{r}
NYC_subway_clean <- NYC_subway_clean |>
  mutate(across(starts_with("route"), as.character))

NYC_subway_tidy <- 
  pivot_longer(
    NYC_subway_clean, 
    route1:route11, 
    names_to = "route_number", 
    names_prefix = "route", 
    values_to = "route_name"
  )
NYC_subway_tidy
```

- How many distinct stations serve the A train?
```{r}
A_station_num <- NYC_subway_tidy |>
  filter(route_name == "A") |>
  distinct(line, station_name) |>
  nrow()
A_station_num
```

- Of the stations that serve the A train, how many are ADA compliant?
```{r}
A_ADA_station_num <- NYC_subway_tidy |>
  filter(route_name == "A" & ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()
A_ADA_station_num
```


# Problem 2
### 1.Read and clean the Mr. Trash Wheel sheet
```{r}
trash_wheel <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                          skip = 1, 
                          sheet = "Mr. Trash Wheel", 
                          na = c("NA",".","")) |>
  janitor::clean_names()

trash_wheel_clean <- trash_wheel |>
  filter(!is.na(dumpster)) |> 
  mutate(sports_balls = round(sports_balls) |>
           as.integer(), year = as.double(year)) |>
  mutate(trash_w = "mr.")
trash_wheel_clean
```

### 2.Import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine this with the Mr. Trash Wheel dataset.
```{r}
pro_trash_wheel <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                              skip = 1, 
                              sheet = "Professor Trash Wheel", 
                              na = c("NA",".","")) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>
  mutate(trash_w = "professor")
```

```{r}
gwy_trash_wheel <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                              skip = 1, 
                              sheet = "Gwynnda Trash Wheel", 
                              na = c("NA",".","")) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>
  mutate(trash_w = "gwynnda")
```

```{r}
trash_wheel_three <- bind_rows(trash_wheel_clean, pro_trash_wheel, gwy_trash_wheel)
```

### 3.Description about these data
Based on the provided Trash Wheel dataset, after data cleaning and combination, there are `r nrow(trash_wheel_three)` observations in the resulting dataset. The data records the amount of different kins of trash collected by various Trash Wheels, with key variables including `weight_tons` (the total weight of trash), `date` and so on.

- What was the total weight of trash collected by Professor Trash Wheel? 
```{r}
total_weight_pro <- trash_wheel_three |>
  filter(trash_w == "professor") |>
  summarise(total_weight = sum(weight_tons, na.rm = TRUE)) |>
  pull(total_weight)
total_weight_pro
```

- What was the total number of cigarette butts collected by Gwynnda in June of 2022?
```{r}
total_weight_pro <- trash_wheel_three |>
  filter(trash_w == "gwynnda" & year == 2022 & month == "June") |>
  summarise(total_ciga_num = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(total_ciga_num)
total_weight_pro
```


# Problem 3
### 1.Create and export a single, well-organized dataset, named `gbb`
- import, clean, tidy, and otherwise wrangle each of these datasets
```{r}
bakers <- read_csv("./data/gbb_datasets/bakers.csv", na = c("N/A","NA"," ")) |>
  janitor::clean_names() |>
  rename(full_name = baker_name)
bakers
```

```{r}
bakes <- read_csv("./data/gbb_datasets/bakes.csv", na = c("N/A","NA"," ")) |>
  janitor::clean_names()
bakes
```

```{r}
results <- read_csv("./data/gbb_datasets/results.csv", skip = 2, na = c("N/A","NA"," ")) |>
  janitor::clean_names()
results
```

- check for completeness and correctness across datasets
```{r}
# bakers & bakes
bakers <- bakers |>
  mutate(baker = str_extract(full_name, "^[^ ]+"))

missing_bakes_bakers <- bakes |>
  anti_join(bakers, by = c("baker", "series"))

missing_bakers_bakes <- bakers |>
  anti_join(bakes, by = c("baker", "series"))

missing_bakes_bakers
missing_bakers_bakes
```

```{r}
# bakers & results
missing_results_bakers <- results |>
  anti_join(bakers, by = c("baker", "series"))

missing_bakers_results <- bakers |>
  anti_join(results, by = c("baker", "series"))

missing_results_bakers
missing_bakers_results
```

```{r}
# bakes & results
missing_results_bakes <- results |>
  anti_join(bakes, by = c("baker", "series"))

missing_bakes_results <- bakes |>
  anti_join(results, by = c("baker", "series"))

missing_results_bakes
missing_bakes_results
```

- Unify "Jo Wheatley" in bakers, "'Jo'" in bakes and "Joanne" in results
```{r}
bakes_clean <- bakes |>
  mutate(bakes, baker = str_replace(baker, "\"Jo\"", "Jo"))
results_clean <- results |>
  mutate(results, baker = str_replace(baker, "Joanne", "Jo"))
```

note: `bakes` dataset still lacks 9 and 10 series data.

- merge to create a single, final dataset and organize it
```{r}
results_bakers <- results_clean |> 
  left_join(bakers, by = c("baker", "series"))

gbb <- results_bakers |> 
  left_join(bakes_clean, by = c("baker", "series", "episode")) |>
  select(baker, full_name, everything())
gbb
```

- Export the result as a CSV
```{r}
write_csv(gbb, "./data/gbb_datasets/gbb.csv")
```

### 2.Describe data cleaning process and discuss the final dataset.
- I imported the bakers, bakes and results data sets respectively, renamed the *baker_name* column in bakers to *full_name*, extracted the first name of all Bakers and named it *baker*.
- I used the "anti_join" function to compare the three datasets in pairs, and found that there was a baker whose name was not uniform in the three tables, so she was collectively called "Jo" for the purpose of subsequent table merger. In addition, the bakes table lacks data for the 9th and 10th quarters.
- Merge three forms into **gbb**


### 3.Create a table showing the star baker or winner of each episode in Seasons 5 through 10.
```{r}
star_baker_winner <- gbb |>
  filter(series >= 5 & series <= 10, result %in% c("STAR BAKER", "WINNER")) |>
  select(series, episode, baker, result) |>
  arrange(series, episode)
star_baker_winner
```

- **predictable overall winners:** Nadiya for S6, Candice for S7, Sophie for S8, Rahul for S9  
- **surprises:** Nancy for S5, David for S10  

### 4.`viewers` dataset
- import and show the first 10 rows of this dataset
```{r}
viewers <- read_csv("./data/gbb_datasets/viewers.csv", na = c("N/A","NA"," ")) |>
  janitor::clean_names()

viewers_tidy <-
  pivot_longer(
  viewers,
  series_1:series_10,
  names_to = "series",
  names_prefix = "series_",
  values_to = "viewership"
  )

head(viewers_tidy, 10)
```

- What was the average viewership in Season 1?
```{r}
avg_viewers_s1 <- viewers_tidy |>
  filter(series == "1") |>
  summarise(avg_viewership = mean(viewership, na.rm = TRUE))
avg_viewers_s1
```

- In Season 5?
```{r}
avg_viewers_s5 <- viewers_tidy |>
  filter(series == "5") |>
  summarise(avg_viewership = mean(viewership, na.rm = TRUE))
avg_viewers_s5
```

