p8105_hw2_lz3014
================
2024-10-02

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

# problem 1

### 1.Read, clean and convert the data

``` r
NYC_subway <- read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
                       na = c("NA",".",""))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
NYC_subway_clean <- janitor::clean_names(NYC_subway) |>
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) |>
  mutate(entry = case_match(entry, "YES" ~ TRUE, "NO" ~ FALSE))
NYC_subway_clean
```

    ## # A tibble: 1,868 × 19
    ##    line     station_name station_latitude station_longitude route1 route2 route3
    ##    <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  4 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  5 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  6 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  7 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  8 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  9 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ## 10 4 Avenue 53rd St                  40.6             -74.0 R      <NA>   <NA>  
    ## # ℹ 1,858 more rows
    ## # ℹ 12 more variables: route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <dbl>, route9 <dbl>, route10 <dbl>, route11 <dbl>, entry <lgl>,
    ## #   vending <chr>, entrance_type <chr>, ada <lgl>

### 2.Simple info about this dataset

This dataset contains various variabels related to subways in New York,
including *line*, *station name*, *station latitude and longitude*,
*routes*, *entry*, *ADA compliance* and so on. To clean the data,
firstly, I imported the dataset and used `janitor::clean_names` function
to clean up variable names. Then, I used `select` to retain the required
variables. Finally, I used `case_match` function to convert the *entry*
from character to a logical variable.

After data cleaning process, this data has 1868 rows and 19 columns.
These data are not tidy since from route1to route11 can be reduced to
one variable.

### 3.Answer 3 questions

- How many distinct stations are there?

``` r
station_num <- distinct(NYC_subway_clean, line, station_name) |>
  nrow()
station_num
```

    ## [1] 465

- How many stations are ADA compliant?

``` r
ADA_station_num <- NYC_subway_clean |>
  filter(ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()
ADA_station_num
```

    ## [1] 84

- What proportion of station entrances / exits without vending allow
  entrance?

``` r
ee_novend_en_num <- NYC_subway_clean |>
  filter(vending == "NO" & entry == TRUE) |>
  nrow()
proportion <- ee_novend_en_num/nrow(NYC_subway_clean)
proportion
```

    ## [1] 0.0369379

### 4.Reformat data and 2 questions

``` r
NYC_subway_clean <- NYC_subway_clean |>
  mutate(across(starts_with("route"), as.character))

NYC_subway_tidy <- 
  pivot_longer(
    NYC_subway_clean, 
    route1:route11, 
    names_to = "route_number", 
    names_prefix = "route", 
    values_to = "route_name"
  )
NYC_subway_tidy
```

    ## # A tibble: 20,548 × 10
    ##    line     station_name station_latitude station_longitude entry vending
    ##    <chr>    <chr>                   <dbl>             <dbl> <lgl> <chr>  
    ##  1 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  2 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  3 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  4 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  5 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  6 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  7 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  8 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  9 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ## 10 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ## # ℹ 20,538 more rows
    ## # ℹ 4 more variables: entrance_type <chr>, ada <lgl>, route_number <chr>,
    ## #   route_name <chr>

- How many distinct stations serve the A train?

``` r
A_station_num <- NYC_subway_tidy |>
  filter(route_name == "A") |>
  distinct(line, station_name) |>
  nrow()
A_station_num
```

    ## [1] 60

- Of the stations that serve the A train, how many are ADA compliant?

``` r
A_ADA_station_num <- NYC_subway_tidy |>
  filter(route_name == "A" & ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()
A_ADA_station_num
```

    ## [1] 17

# Problem 2

### 1.Read and clean the Mr. Trash Wheel sheet

``` r
trash_wheel <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                          skip = 1, 
                          sheet = "Mr. Trash Wheel", 
                          na = c("NA",".","")) |>
  janitor::clean_names()
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
trash_wheel_clean <- trash_wheel |>
  filter(!is.na(dumpster)) |> 
  mutate(sports_balls = round(sports_balls) |>
           as.integer(), year = as.double(year)) |>
  mutate(trash_w = "mr.")
trash_wheel_clean
```

    ## # A tibble: 651 × 17
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 641 more rows
    ## # ℹ 11 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, x15 <lgl>,
    ## #   x16 <lgl>, trash_w <chr>

### 2.Import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine this with the Mr. Trash Wheel dataset.

``` r
pro_trash_wheel <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                              skip = 1, 
                              sheet = "Professor Trash Wheel", 
                              na = c("NA",".","")) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>
  mutate(trash_w = "professor")
```

``` r
gwy_trash_wheel <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                              skip = 1, 
                              sheet = "Gwynnda Trash Wheel", 
                              na = c("NA",".","")) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>
  mutate(trash_w = "gwynnda")
```

``` r
trash_wheel_three <- bind_rows(trash_wheel_clean, pro_trash_wheel, gwy_trash_wheel)
```

### 3.Description about these data

Based on the provided Trash Wheel dataset, after data cleaning and
combination, there are 1033 observations in the resulting dataset. The
data records the amount of different kins of trash collected by various
Trash Wheels, with key variables including `weight_tons` (the total
weight of trash), `date` and so on.

- What was the total weight of trash collected by Professor Trash Wheel?

``` r
total_weight_pro <- trash_wheel_three |>
  filter(trash_w == "professor") |>
  summarise(total_weight = sum(weight_tons, na.rm = TRUE)) |>
  pull(total_weight)
total_weight_pro
```

    ## [1] 246.74

- What was the total number of cigarette butts collected by Gwynnda in
  June of 2022?

``` r
total_weight_pro <- trash_wheel_three |>
  filter(trash_w == "gwynnda" & year == 2022 & month == "June") |>
  summarise(total_ciga_num = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(total_ciga_num)
total_weight_pro
```

    ## [1] 18120

# Problem 3

### 1.Create and export a single, well-organized dataset, named `gbb`

- import, clean, tidy, and otherwise wrangle each of these datasets

``` r
bakers <- read_csv("./data/gbb_datasets/bakers.csv", na = c("N/A","NA"," ")) |>
  janitor::clean_names() |>
  rename(full_name = baker_name)
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakers
```

    ## # A tibble: 120 × 5
    ##    full_name        series baker_age baker_occupation             hometown      
    ##    <chr>             <dbl>     <dbl> <chr>                        <chr>         
    ##  1 Ali Imdad             4        25 Charity worker               Saltley, Birm…
    ##  2 Alice Fevronia       10        28 Geography teacher            Essex         
    ##  3 Alvin Magallanes      6        37 Nurse                        Bracknell, Be…
    ##  4 Amelia LeBruin       10        24 Fashion designer             Halifax       
    ##  5 Andrew Smyth          7        25 Aerospace engineer           Derby / Holyw…
    ##  6 Annetha Mills         1        30 Midwife                      Essex         
    ##  7 Antony Amourdoux      9        30 Banker                       London        
    ##  8 Beca Lyne-Pirkis      4        31 Military Wives' Choir Singer Aldershot, Ha…
    ##  9 Ben Frazer            2        31 Graphic Designer             Northampton   
    ## 10 Benjamina Ebuehi      7        23 Teaching assistant           South London  
    ## # ℹ 110 more rows

``` r
bakes <- read_csv("./data/gbb_datasets/bakes.csv", na = c("N/A","NA"," ")) |>
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes
```

    ## # A tibble: 548 × 5
    ##    series episode baker     signature_bake                          show_stopper
    ##     <dbl>   <dbl> <chr>     <chr>                                   <chr>       
    ##  1      1       1 Annetha   "Light Jamaican Black Cakewith Strawbe… Red, White …
    ##  2      1       1 David     "Chocolate Orange Cake"                 Black Fores…
    ##  3      1       1 Edd       "Caramel Cinnamon and Banana Cake"      <NA>        
    ##  4      1       1 Jasminder "Fresh Mango and Passion Fruit Humming… <NA>        
    ##  5      1       1 Jonathan  "Carrot Cake with Lime and Cream Chees… Three Tiere…
    ##  6      1       1 Lea       "Cranberry and Pistachio Cakewith Oran… Raspberries…
    ##  7      1       1 Louise    "Carrot and Orange Cake"                Never Fail …
    ##  8      1       1 Mark      "Sticky Marmalade Tea Loaf"             Heart-shape…
    ##  9      1       1 Miranda   "Triple Layered Brownie Meringue Cake\… Three Tiere…
    ## 10      1       1 Ruth      "Three Tiered Lemon Drizzle Cakewith F… Classic Cho…
    ## # ℹ 538 more rows

``` r
results <- read_csv("./data/gbb_datasets/results.csv", skip = 2, na = c("N/A","NA"," ")) |>
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results
```

    ## # A tibble: 1,136 × 5
    ##    series episode baker     technical result
    ##     <dbl>   <dbl> <chr>         <dbl> <chr> 
    ##  1      1       1 Annetha           2 IN    
    ##  2      1       1 David             3 IN    
    ##  3      1       1 Edd               1 IN    
    ##  4      1       1 Jasminder        NA IN    
    ##  5      1       1 Jonathan          9 IN    
    ##  6      1       1 Louise           NA IN    
    ##  7      1       1 Miranda           8 IN    
    ##  8      1       1 Ruth             NA IN    
    ##  9      1       1 Lea              10 OUT   
    ## 10      1       1 Mark             NA OUT   
    ## # ℹ 1,126 more rows

- check for completeness and correctness across datasets

``` r
# bakers & bakes
bakers <- bakers |>
  mutate(baker = str_extract(full_name, "^[^ ]+"))

missing_bakes_bakers <- bakes |>
  anti_join(bakers, by = c("baker", "series"))

missing_bakers_bakes <- bakers |>
  anti_join(bakes, by = c("baker", "series"))

missing_bakes_bakers
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

``` r
missing_bakers_bakes
```

    ## # A tibble: 26 × 6
    ##    full_name           series baker_age baker_occupation          hometown baker
    ##    <chr>                <dbl>     <dbl> <chr>                     <chr>    <chr>
    ##  1 Alice Fevronia          10        28 Geography teacher         Essex    Alice
    ##  2 Amelia LeBruin          10        24 Fashion designer          Halifax  Amel…
    ##  3 Antony Amourdoux         9        30 Banker                    London   Anto…
    ##  4 Briony Williams          9        33 Full-time parent          Bristol  Brio…
    ##  5 Dan Beasley-Harling      9        36 Full-time parent          London   Dan  
    ##  6 Dan Chambers            10        32 Support worker            Rotherh… Dan  
    ##  7 David Atherton          10        36 International health adv… Whitby   David
    ##  8 Helena Garcia           10        40 Online project manager    Leeds    Hele…
    ##  9 Henry Bird              10        20 Student                   Durham   Henry
    ## 10 Imelda McCarron          9        33 Countryside recreation o… County … Imel…
    ## # ℹ 16 more rows

``` r
# bakers & results
missing_results_bakers <- results |>
  anti_join(bakers, by = c("baker", "series"))

missing_bakers_results <- bakers |>
  anti_join(results, by = c("baker", "series"))

missing_results_bakers
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 Joanne        11 IN        
    ## 2      2       2 Joanne        10 IN        
    ## 3      2       3 Joanne         1 IN        
    ## 4      2       4 Joanne         8 IN        
    ## 5      2       5 Joanne         6 IN        
    ## 6      2       6 Joanne         1 STAR BAKER
    ## 7      2       7 Joanne         3 IN        
    ## 8      2       8 Joanne         1 WINNER

``` r
missing_bakers_results
```

    ## # A tibble: 1 × 6
    ##   full_name   series baker_age baker_occupation hometown     baker
    ##   <chr>        <dbl>     <dbl> <chr>            <chr>        <chr>
    ## 1 Jo Wheatley      2        41 Housewife        Ongar, Essex Jo

``` r
# bakes & results
missing_results_bakes <- results |>
  anti_join(bakes, by = c("baker", "series"))

missing_bakes_results <- bakes |>
  anti_join(results, by = c("baker", "series"))

missing_results_bakes
```

    ## # A tibble: 258 × 5
    ##    series episode baker  technical result    
    ##     <dbl>   <dbl> <chr>      <dbl> <chr>     
    ##  1      2       1 Joanne        11 IN        
    ##  2      2       2 Joanne        10 IN        
    ##  3      2       3 Joanne         1 IN        
    ##  4      2       4 Joanne         8 IN        
    ##  5      2       5 Joanne         6 IN        
    ##  6      2       6 Joanne         1 STAR BAKER
    ##  7      2       7 Joanne         3 IN        
    ##  8      2       8 Joanne         1 WINNER    
    ##  9      9       1 Antony        12 IN        
    ## 10      9       1 Briony         2 IN        
    ## # ℹ 248 more rows

``` r
missing_bakes_results
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

- Unify “Jo Wheatley” in bakers, “‘Jo’” in bakes and “Joanne” in results

``` r
bakes_clean <- bakes |>
  mutate(bakes, baker = str_replace(baker, "\"Jo\"", "Jo"))
results_clean <- results |>
  mutate(results, baker = str_replace(baker, "Joanne", "Jo"))
```

note: `bakes` dataset still lacks 9 and 10 series data.

- merge to create a single, final dataset and organize it

``` r
results_bakers <- results_clean |> 
  left_join(bakers, by = c("baker", "series"))

gbb <- results_bakers |> 
  left_join(bakes_clean, by = c("baker", "series", "episode")) |>
  select(baker, full_name, everything())
gbb
```

    ## # A tibble: 1,136 × 11
    ##    baker    full_name series episode technical result baker_age baker_occupation
    ##    <chr>    <chr>      <dbl>   <dbl>     <dbl> <chr>      <dbl> <chr>           
    ##  1 Annetha  Annetha …      1       1         2 IN            30 Midwife         
    ##  2 David    David Ch…      1       1         3 IN            31 Entrepreneur    
    ##  3 Edd      Edd Kimb…      1       1         1 IN            24 Debt collector …
    ##  4 Jasmind… Jasminde…      1       1        NA IN            45 Assistant Credi…
    ##  5 Jonathan Jonathan…      1       1         9 IN            25 Research Analyst
    ##  6 Louise   Louise B…      1       1        NA IN            44 Police Officer  
    ##  7 Miranda  Miranda …      1       1         8 IN            37 Food buyer for …
    ##  8 Ruth     Ruth Cle…      1       1        NA IN            31 Retail manager/…
    ##  9 Lea      Lea Harr…      1       1        10 OUT           51 Retired         
    ## 10 Mark     Mark Whi…      1       1        NA OUT           48 Bus Driver      
    ## # ℹ 1,126 more rows
    ## # ℹ 3 more variables: hometown <chr>, signature_bake <chr>, show_stopper <chr>

- Export the result as a CSV

``` r
write_csv(gbb, "./data/gbb_datasets/gbb.csv")
```

### 2.Describe data cleaning process and discuss the final dataset.

### 3.Create a table showing the star baker or winner of each episode in Seasons 5 through 10.

``` r
star_baker_winner <- gbb |>
  filter(series >= 5 & series <= 10, result %in% c("STAR BAKER", "WINNER")) |>
  select(series, episode, baker, result) |>
  arrange(series, episode)
star_baker_winner
```

    ## # A tibble: 60 × 4
    ##    series episode baker   result    
    ##     <dbl>   <dbl> <chr>   <chr>     
    ##  1      5       1 Nancy   STAR BAKER
    ##  2      5       2 Richard STAR BAKER
    ##  3      5       3 Luis    STAR BAKER
    ##  4      5       4 Richard STAR BAKER
    ##  5      5       5 Kate    STAR BAKER
    ##  6      5       6 Chetna  STAR BAKER
    ##  7      5       7 Richard STAR BAKER
    ##  8      5       8 Richard STAR BAKER
    ##  9      5       9 Richard STAR BAKER
    ## 10      5      10 Nancy   WINNER    
    ## # ℹ 50 more rows

- **predictable overall winners:** Nadiya for S6, Candice for S7, Sophie
  for S8, Rahul for S9  
- **surprises:** Nancy for S5, David for S10

### 4.`viewers` dataset

- import and show the first 10 rows of this dataset

``` r
viewers <- read_csv("./data/gbb_datasets/viewers.csv", na = c("N/A","NA"," ")) |>
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
viewers_tidy <-
  pivot_longer(
  viewers,
  series_1:series_10,
  names_to = "series",
  names_prefix = "series_",
  values_to = "viewership"
  )

head(viewers_tidy, 10)
```

    ## # A tibble: 10 × 3
    ##    episode series viewership
    ##      <dbl> <chr>       <dbl>
    ##  1       1 1            2.24
    ##  2       1 2            3.1 
    ##  3       1 3            3.85
    ##  4       1 4            6.6 
    ##  5       1 5            8.51
    ##  6       1 6           11.6 
    ##  7       1 7           13.6 
    ##  8       1 8            9.46
    ##  9       1 9            9.55
    ## 10       1 10           9.62

- What was the average viewership in Season 1?

``` r
avg_viewers_s1 <- viewers_tidy |>
  filter(series == "1") |>
  summarise(avg_viewership = mean(viewership, na.rm = TRUE))
avg_viewers_s1
```

    ## # A tibble: 1 × 1
    ##   avg_viewership
    ##            <dbl>
    ## 1           2.77

- In Season 5?

``` r
avg_viewers_s5 <- viewers_tidy |>
  filter(series == "5") |>
  summarise(avg_viewership = mean(viewership, na.rm = TRUE))
avg_viewers_s5
```

    ## # A tibble: 1 × 1
    ##   avg_viewership
    ##            <dbl>
    ## 1           10.0
